{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d2d3e9-35f3-4748-8c96-802def97aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MllamaConfig, MllamaForConditionalGeneration\n",
    "from accelerate import init_empty_weights\n",
    "from torch.nn import ModuleList\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330a813c-f8c2-46f0-9600-fd4c6e257863",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/Llama-3.2-11B-Vision-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37ba017-19a4-43fb-b0df-f7cc4f8b89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MllamaConfig.from_pretrained(model_id)\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = MllamaForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8e7840-fc9f-4289-9250-aa623c0ca011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_named_children(mdl, result: list[str], parent: list[str]|None=None, recurse: bool=True):\n",
    "    if parent is None:\n",
    "        parent = []\n",
    "\n",
    "    for n, m in mdl.named_children():\n",
    "        names = list(parent) # copy\n",
    "        names.append(n)\n",
    "\n",
    "        is_list = isinstance(m, ModuleList)\n",
    "        has_params = len(list(m.parameters(recurse=False))) > 0\n",
    "        has_buffers = len(list(m.buffers(recurse=False))) > 0\n",
    "\n",
    "        if has_params or has_buffers or not recurse:\n",
    "            #print(f\"{'.'.join(names)}\")\n",
    "            result.append('.'.join(names))\n",
    "\n",
    "        if recurse:\n",
    "            gather_named_children(m, result, parent=names, recurse=not is_list)\n",
    "\n",
    "result: list[str] = []\n",
    "gather_named_children(model, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb49ecd9-ab88-4746-8ae5-99a517d1c931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('vision_model', 0),\n",
       "             ('vision_model.patch_embedding', 0),\n",
       "             ('vision_model.gated_positional_embedding', 0),\n",
       "             ('vision_model.gated_positional_embedding.tile_embedding', 0),\n",
       "             ('vision_model.pre_tile_positional_embedding', 0),\n",
       "             ('vision_model.pre_tile_positional_embedding.embedding', 0),\n",
       "             ('vision_model.post_tile_positional_embedding', 0),\n",
       "             ('vision_model.post_tile_positional_embedding.embedding', 0),\n",
       "             ('vision_model.layernorm_pre', 0),\n",
       "             ('vision_model.layernorm_post', 0),\n",
       "             ('vision_model.transformer.layers.0', 0),\n",
       "             ('vision_model.transformer.layers.1', 0),\n",
       "             ('vision_model.transformer.layers.2', 0),\n",
       "             ('vision_model.transformer.layers.3', 0),\n",
       "             ('vision_model.transformer.layers.4', 0),\n",
       "             ('vision_model.transformer.layers.5', 0),\n",
       "             ('vision_model.transformer.layers.6', 0),\n",
       "             ('vision_model.transformer.layers.7', 0),\n",
       "             ('vision_model.transformer.layers.8', 0),\n",
       "             ('vision_model.transformer.layers.9', 0),\n",
       "             ('vision_model.transformer.layers.10', 0),\n",
       "             ('vision_model.transformer.layers.11', 0),\n",
       "             ('vision_model.transformer.layers.12', 0),\n",
       "             ('vision_model.transformer.layers.13', 0),\n",
       "             ('vision_model.transformer.layers.14', 0),\n",
       "             ('vision_model.transformer.layers.15', 0),\n",
       "             ('vision_model.transformer.layers.16', 0),\n",
       "             ('vision_model.transformer.layers.17', 0),\n",
       "             ('vision_model.transformer.layers.18', 0),\n",
       "             ('vision_model.transformer.layers.19', 0),\n",
       "             ('vision_model.transformer.layers.20', 0),\n",
       "             ('vision_model.transformer.layers.21', 0),\n",
       "             ('vision_model.transformer.layers.22', 0),\n",
       "             ('vision_model.transformer.layers.23', 0),\n",
       "             ('vision_model.transformer.layers.24', 0),\n",
       "             ('vision_model.transformer.layers.25', 0),\n",
       "             ('vision_model.transformer.layers.26', 0),\n",
       "             ('vision_model.transformer.layers.27', 0),\n",
       "             ('vision_model.transformer.layers.28', 0),\n",
       "             ('vision_model.transformer.layers.29', 0),\n",
       "             ('vision_model.transformer.layers.30', 0),\n",
       "             ('vision_model.transformer.layers.31', 0),\n",
       "             ('vision_model.global_transformer.layers.0', 0),\n",
       "             ('vision_model.global_transformer.layers.1', 0),\n",
       "             ('vision_model.global_transformer.layers.2', 0),\n",
       "             ('vision_model.global_transformer.layers.3', 0),\n",
       "             ('vision_model.global_transformer.layers.4', 0),\n",
       "             ('vision_model.global_transformer.layers.5', 0),\n",
       "             ('vision_model.global_transformer.layers.6', 0),\n",
       "             ('vision_model.global_transformer.layers.7', 0),\n",
       "             ('language_model.model.embed_tokens', 0),\n",
       "             ('language_model.model.layers.0', 0),\n",
       "             ('language_model.model.layers.1', 0),\n",
       "             ('language_model.model.layers.2', 0),\n",
       "             ('language_model.model.layers.3', 0),\n",
       "             ('language_model.model.layers.4', 0),\n",
       "             ('language_model.model.layers.5', 0),\n",
       "             ('language_model.model.layers.6', 0),\n",
       "             ('language_model.model.layers.7', 0),\n",
       "             ('language_model.model.layers.8', 0),\n",
       "             ('language_model.model.layers.9', 0),\n",
       "             ('language_model.model.layers.10', 0),\n",
       "             ('language_model.model.layers.11', 0),\n",
       "             ('language_model.model.layers.12', 0),\n",
       "             ('language_model.model.layers.13', 0),\n",
       "             ('language_model.model.layers.14', 0),\n",
       "             ('language_model.model.layers.15', 0),\n",
       "             ('language_model.model.layers.16', 0),\n",
       "             ('language_model.model.layers.17', 0),\n",
       "             ('language_model.model.layers.18', 0),\n",
       "             ('language_model.model.layers.19', 0),\n",
       "             ('language_model.model.layers.20', 0),\n",
       "             ('language_model.model.layers.21', 0),\n",
       "             ('language_model.model.layers.22', 0),\n",
       "             ('language_model.model.layers.23', 0),\n",
       "             ('language_model.model.layers.24', 0),\n",
       "             ('language_model.model.layers.25', 0),\n",
       "             ('language_model.model.layers.26', 0),\n",
       "             ('language_model.model.layers.27', 0),\n",
       "             ('language_model.model.layers.28', 0),\n",
       "             ('language_model.model.layers.29', 0),\n",
       "             ('language_model.model.layers.30', 0),\n",
       "             ('language_model.model.layers.31', 0),\n",
       "             ('language_model.model.layers.32', 0),\n",
       "             ('language_model.model.layers.33', 0),\n",
       "             ('language_model.model.layers.34', 0),\n",
       "             ('language_model.model.layers.35', 0),\n",
       "             ('language_model.model.layers.36', 0),\n",
       "             ('language_model.model.layers.37', 0),\n",
       "             ('language_model.model.layers.38', 0),\n",
       "             ('language_model.model.layers.39', 0),\n",
       "             ('language_model.model.norm', 0),\n",
       "             ('language_model.model.rotary_emb', 0),\n",
       "             ('language_model.lm_head', 0),\n",
       "             ('multi_modal_projector', 0)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_map = OrderedDict([\n",
    "    (n, 0) for n in result\n",
    "])\n",
    "\n",
    "device_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
