{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89aa2965-abeb-43f7-967a-f2858978b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "from optimum.quanto import QuantizedModelForCausalLM, qint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e65aa8-0baf-4d85-8ed8-965339fae572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = 'meta-llama/Llama-3.2-11B-Vision-Instruct'\n",
    "model_id = 'Llama-3.2-11B-Vision-Instruct'\n",
    "\n",
    "dest = 'Llama-3.2-11B-Vision-Instruct-qint8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941226d-796a-405c-ad93-8e00110621a3",
   "metadata": {},
   "source": [
    "I'm not sure if there's a better way to do this, but yes, you have to load the entire thing into system memory at float32 precision before quantizing it.\n",
    "\n",
    "Forcing the dtype to anything else will result in errors during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b786a2ba-7726-4ead-a66a-8bb6989c9e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efd491c25974818a17271734c172f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MllamaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float32)\n",
    "qmodel = QuantizedModelForCausalLM.quantize(model, weights=qint8, exclude=[\n",
    "    'language_model.lm_head',\n",
    "    'multi_modal_projector',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e8fb26-a0cf-45e7-9cfd-0c20a296dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel.save_pretrained(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8366ff1e-d6d1-439d-8706-963b7c6b842c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "processor.save_pretrained(dest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
